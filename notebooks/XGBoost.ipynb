{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddabdf5b-99c1-4750-9ad7-c2d9453a61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()\n",
    "import os\n",
    "import random \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffa8ffb-2b9e-4620-baf8-92602706e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:37:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haicore-project-covchl/do8557/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=20, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in original data\n",
    "train_data = \"hida_workspace/trainSet/trainSet.txt\"\n",
    "test_data = \"hida_workspace/testSet/testSet.txt\"\n",
    "\n",
    "df_train = pd.read_csv(train_data)\n",
    "df_train_length_idx = len(df_train)\n",
    "df_test = pd.read_csv(test_data)\n",
    "\n",
    "# Merge the two datasets\n",
    "train_test = [df_train, df_test]\n",
    "df_train_test = pd.concat(train_test)\n",
    "# df_train_test['Prognosis'].loc[df_train_test['Prognosis'] == '<undefined>'] = np.nan\n",
    "df_train_test.loc[df_train_test['Prognosis'] == '<undefined>', 'Prognosis'] = np.nan\n",
    "\n",
    "# all variables in the dataset (incl. outcome)\n",
    "variables = list(df_train_test.columns[3:])\n",
    "\n",
    "\n",
    "# read in csv from Tobias (imputed via catboost\n",
    "df_imputed_train = pd.read_csv(\"Results/Tobias/imputed_train.csv\")\n",
    "df_imputed_test = pd.read_csv(\"Results/Tobias/imputed_test.csv\")\n",
    "\n",
    "\n",
    "df_for_rf = df_train.copy()\n",
    "df_for_rf[\"Prognosis\"] = df_for_rf[\"Prognosis\"].astype(\"category\").cat.codes\n",
    "df_for_rf = df_for_rf[variables]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get predictions from xgboost imputed:\n",
    "xgboost_features = variables.copy()\n",
    "xgboost_features.remove(\"Prognosis\")\n",
    "\n",
    "train_valid_split = 0.9\n",
    "sep_index = int(863 * train_valid_split)\n",
    "\n",
    "X_train = df_imputed_train[xgboost_features].iloc[0:sep_index]\n",
    "y_train = df_imputed_train[\"Prognosis\"].iloc[0:sep_index]\n",
    "\n",
    "X_test = df_imputed_train[xgboost_features].iloc[sep_index:]\n",
    "y_test = df_imputed_train[\"Prognosis\"].iloc[sep_index:]\n",
    "\n",
    "\n",
    "# fit the model \n",
    "#model = CatBoostClassifier(verbose=0, iterations=1000, task_type=\"GPU\", devices='0:1')\n",
    "#model.fit(X_train.values, y_train.values)\n",
    "\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# make a prediction\n",
    "#yhat = model.predict(X_test.values)\n",
    "\n",
    "#catboost_imputed_results = dict(predictions_cb_imputed=list(yhat), images=image_names.to_list(), targets=y_test.values)\n",
    "#catboost_imputed_results_df = pd.DataFrame(catboost_imputed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f616515-47f7-42af-8ed6-802920d48259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=20, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e41237-b7ea-4f9d-a6e9-02dd5f8f64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haicore-project-covchl/do8557/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a840d574c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxgboost_imputed_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_cb_imputed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mxgboost_imputed_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgboost_imputed_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_names' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test.values)\n",
    "xgboost_imputed_results = dict(predictions_xg_imputed=list(y_pred), images=image_names.to_list(), targets=y_test.values)\n",
    "xgboost_imputed_results_df = pd.DataFrame(xgboost_imputed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e3ff8c-8ff3-4b91-8399-d911d014727c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776    1.0\n",
       "777    1.0\n",
       "778    0.0\n",
       "779    1.0\n",
       "780    1.0\n",
       "      ... \n",
       "858    1.0\n",
       "859    1.0\n",
       "860    0.0\n",
       "861    1.0\n",
       "862    0.0\n",
       "Name: Prognosis, Length: 87, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ffb58-ad10-458d-a7bc-ec3cf186f638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8874a27-9615-4fc3-b687-cd8f2e9a0743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adecc22-23d6-40f2-9d46-279c6e0f28f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d1117-53ae-4387-b94b-fc9e2b70cebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
